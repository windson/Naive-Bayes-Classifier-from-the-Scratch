{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Navule Pavan Kumar Rao\n",
    "## Naive Bayes Implementation from the scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the Email dataset from https://drive.google.com/file/d/0BxNo5NMmppJ1eW1leW9xbDFXTUk/view. This dataset is from Lingspam dataset. There are two types of emails, \"spam\" and \"non-spam\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, errno, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder=\"data\\\\2\\\\EmailsData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filenames(train_test):\n",
    "    folder_spam=''\n",
    "    folder_non_spam=''\n",
    "    #define folder paths\n",
    "    if train_test == 'train':\n",
    "        folder_spam =os.path.join(os.path.dirname('__file__'), data_folder + '\\\\spam-train')\n",
    "        folder_non_spam = os.path.join(os.path.dirname('__file__'), data_folder + '\\\\nonspam-train')\n",
    "    elif train_test == 'test':\n",
    "        folder_spam =os.path.join(os.path.dirname('__file__'), data_folder + '\\\\spam-test')\n",
    "        folder_non_spam = os.path.join(os.path.dirname('__file__'), data_folder + '\\\\nonspam-test')\n",
    "    # get all file names in training\n",
    "    fn_spm=[os.path.join(folder_spam, each)\n",
    "            for each in os.listdir(folder_spam)]\n",
    "    fn_non_spm = [os.path.join(folder_non_spam, each)\n",
    "            for each in os.listdir(folder_non_spam)]\n",
    "    return fn_spm,fn_non_spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_email_text_file_names_and_targets():\n",
    "    tr_spm,tr_non_spm = get_filenames('train')\n",
    "    tst_spm,tst_non_spm=get_filenames('test')\n",
    "    train_fn=np.append(tr_spm,tr_non_spm)\n",
    "    test_fn=np.append(tst_spm,tst_non_spm)\n",
    "    print(' training spam:{0} \\n training non-spam:{1} \\n test spam:{2} \\n test non-spam {3} '.format(len(tr_spm),len(tr_non_spm),len(tst_spm),len(tst_non_spm)))\n",
    "    all_fn=np.append(train_fn,test_fn)\n",
    "    print('total no. of files read {0}'.format(len(all_fn)))\n",
    "    train_target=np.append(np.ones(len(tr_spm),dtype=np.int),np.zeros(len(tr_non_spm),dtype=np.int))\n",
    "    test_target=np.append(np.ones(len(tst_spm),dtype=np.int),np.zeros(len(tst_non_spm),dtype=np.int))\n",
    "    return all_fn, train_target, test_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement own Naive Bayes classifer to categorize emails as \"spam\" or \"non-spam\". To convert the text data into vectors, you can use TfidfVectorizer from here http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize input dataset using TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def get_tf_idf_vector(file_names):\n",
    "    tfidf = TfidfVectorizer(input='filename', \n",
    "                            token_pattern='(?u)\\\\b[a-zA-Z]\\\\w{2,}\\\\b',\n",
    "                            stop_words='english')\n",
    "    vect=tfidf.fit_transform(file_names)\n",
    "    return vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Navie Bayes Implementation"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1\n",
    "##### Implement a method that gets Gaussian Likelihood Formula \n",
    "![\\img\\image.png](attachment:image.png)\n",
    "\n",
    "Where:\n",
    "\n",
    "   µ: Mean or expectation (location of the peak)\n",
    "   \n",
    "   σ: Standard deviation\n",
    "   \n",
    "   x: The independent random variable\n",
    "   \n",
    "Img source: http://www.endmemo.com/statistics/gaussian.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gaussian_likelihood(x, mean, std):\n",
    "    variance=std**2\n",
    "    exponent_func = np.exp(-0.5*((x-mean)/std)**2)\n",
    "    denominator = np.sqrt( 2*np.pi* variance)\n",
    "    gauss=exponent_func/denominator\n",
    "    return gauss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2\n",
    "##### Perform Dimentionality Reduction\n",
    "Reduce the dataset to say, K=50 dimensions in order to improve the variance and decrease the bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "def get_dataset_reduced_to_K_dimensions(data,target,K):\n",
    "    k_selected_fts = SelectKBest(mutual_info_classif, k = K)\n",
    "    ds= k_selected_fts.fit_transform(data, target)\n",
    "    return ds[:700,:], ds[700:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "def generate_report(predicted,actual):\n",
    "    accuracy=len(predicted[predicted == actual])/len(predicted)\n",
    "    print('accuracy:',accuracy)\n",
    "    f1_scr=f1_score( actual, predicted)\n",
    "    print('f1 score:',f1_scr)\n",
    "    confusion_mat=confusion_matrix(actual, predicted)\n",
    "    print('Confusion Matrix: \\n',confusion_mat)\n",
    "    auc=roc_auc_score( actual, predicted)\n",
    "    print('AUC:',auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3\n",
    "##### Implement Navie Bayes classifier \n",
    "\n",
    "Lets build a Custom Navie Bayes that has similar methods to that of scikit learn's GaussianNB ie fit and predict\n",
    "fit() method takes the training data holding attribute values as first arg and target variable collection as second arg\n",
    "predict() method takes the test attributes and returns the predicted outcome target classifications\n",
    "\n",
    "http://blog.hackerearth.com/introduction-naive-bayes-algorithm-codes-python-r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class naive_bayes(object):\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.class_labels = np.unique(y_train)\n",
    "        self.means = {}\n",
    "        self.std = {}\n",
    "        self.y_prob = {}\n",
    "        for c in self.class_labels:\n",
    "            self.means[c] = []\n",
    "            self.std[c] = []\n",
    "            self.y_prob[c] = len( y_train[ y_train == c])/len(y_train)\n",
    "            temp = X_train[y_train == c]\n",
    "            for col in range(temp.shape[1]):\n",
    "                self.means[c].append(temp[:, col].mean())\n",
    "                self.std[c].append(temp[:, col].std())\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        predicted = np.zeros(X_test.shape[0])\n",
    "        count = 0\n",
    "        for row in X_test:\n",
    "            pred_classes = np.zeros(self.class_labels.shape[0])\n",
    "            for c in self.class_labels:\n",
    "                pred_classes[c] = 0\n",
    "                prod = 1\n",
    "                for i in range(len(row)):\n",
    "                    mean = self.means[c][i]\n",
    "                    std  = self.std[c][i]\n",
    "                    '''Skip for 0 variance i.e., square of standard deviation = 0\n",
    "                    this is in order to \n",
    "                    get rid of gaussian distribution calculation has variance in the denominator \n",
    "                    that leads to divide by zero exceptions\n",
    "                    '''\n",
    "                    if std**2 == 0:\n",
    "                        continue\n",
    "                    gaus = get_gaussian_likelihood(row[i], mean,std)\n",
    "                    prod *= gaus\n",
    "                pred_classes[c] = self.y_prob[c] * prod\n",
    "            predicted[count] = self.class_labels[pred_classes.argmax()]\n",
    "            count+=1\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4\n",
    "##### Load input data and Pre-Processing\n",
    "Load data and get tfidf vector which needs to be feed as input for custom naive_bayes and sklearn GaussianNB algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training spam:350 \n",
      " training non-spam:350 \n",
      " test spam:130 \n",
      " test non-spam 130 \n",
      "total no. of files read 960\n",
      "Wall time: 429 ms\n"
     ]
    }
   ],
   "source": [
    "file_names,y_train, y_test = get_all_email_text_file_names_and_targets()\n",
    "%time vector=get_tf_idf_vector(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "target=np.append(y_train, y_test)\n",
    "%time X_train, X_test= get_dataset_reduced_to_K_dimensions(vector.toarray(),target,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5\n",
    "##### Invoke custom naive_bayes Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Naive Bayes on data given in folder \"nonspam-train\" and \"spam-train\". Test it on emails given in folder \"nonspam-test\" and \"spam-test\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 227 ms\n"
     ]
    }
   ],
   "source": [
    "nb = naive_bayes()\n",
    "nb.fit(X_train, y_train)\n",
    "%time custom_predicted = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 6\n",
    "##### Scikit Learn Implementation of Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use sklearn's inbuilt Naive Bayes classifer to train on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "model=nb.fit(X_train, y_train)\n",
    "%time sklrn_predicted=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step7 \n",
    "Report accuracy, F1-score, confusion matrix and area under ROC curve (AUC). Also, report your observations from the result.\n",
    "Compare the performance on test dataset with your implementation.\n",
    "\n",
    "Confusion Matrix generated by sklearn.metrics will have the following structure\n",
    "\n",
    "[[tn, fp] \n",
    "\n",
    "[fn, tp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************\n",
      "Report for Custom Naive Bayes Implementaion\n",
      "*******************************************\n",
      "accuracy: 0.9576923076923077\n",
      "f1 score: 0.95785440613\n",
      "Confusion Matrix: \n",
      " [[124   6]\n",
      " [  5 125]]\n",
      "AUC: 0.957692307692\n",
      "*******************************************\n",
      "Report for scikit-learn Naive Bayes Implementaion\n",
      "*******************************************\n",
      "accuracy: 0.9653846153846154\n",
      "f1 score: 0.966542750929\n",
      "Confusion Matrix: \n",
      " [[121   9]\n",
      " [  0 130]]\n",
      "AUC: 0.965384615385\n",
      "*******************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*******************************************\")\n",
    "print(\"Report for Custom Naive Bayes Implementaion\")\n",
    "print(\"*******************************************\")\n",
    "generate_report(custom_predicted,y_test)\n",
    "print(\"*******************************************\")\n",
    "print(\"Report for scikit-learn Naive Bayes Implementaion\")\n",
    "print(\"*******************************************\")\n",
    "generate_report(sklrn_predicted,y_test)\n",
    "print(\"*******************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations:\n",
    "We notice that the sklearn NB classifier is able to have 0 false negatives compared to 5 with custom implementation and hence the accuracy is more for sklearns NB classifier.\n",
    "    \n",
    "We also observe that the custom implementation and sklearn's Naive Bayes Classifier are having almost similar scores but is expected to vary for large and complex datasets in real time situations    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
